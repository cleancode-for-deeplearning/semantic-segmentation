# -*- coding: utf-8 -*-
"""pytorch_custom_dataset_le.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vtx9d54VCCaaNSqotpj241M4ktnqLVAI
"""

import torch
from torch.utils.data.dataset import Dataset 
from torchvision import transforms
from PIL import Image
import glob

# folder_data = sorted(glob.glob("./data/*.tif"))
# folder_mask = sorted(glob.glob("./masks/*.tif"))

# len_data = len(folder_data)
# train_size = 0.7

# train_image_paths = folder_data[:int(len_data*train_size)]
# test_image_paths = folder_data[int(len_data*train_size):]

# train_mask_paths = folder_mask[:int(len_data*train_size)]
# test_mask_paths = folder_mask[int(len_data*train_size):]

class CustomDataset(Dataset):

    def __init__(self, image_paths, target_paths, train=True):   

        self.image_paths = image_paths
        self.target_paths = target_paths
        self.transforms = transforms.ToTensor()

    def __getitem__(self, index):

        image = Image.open(self.image_paths[index])
        mask = Image.open(self.target_paths[index])
        t_image = self.transforms(image)
        return t_image, mask

    def __len__(self):  

        return len(self.image_paths)

# train_dataset = CustomDataset(train_image_paths, train_mask_paths, train=True)
# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=False)

# test_dataset = CustomDataset(test_image_paths, test_mask_paths, train=False)
# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)
